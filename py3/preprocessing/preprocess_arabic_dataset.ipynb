{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "559b07a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import parse_PAGE\n",
    "import cv2\n",
    "import line_extraction\n",
    "import numpy as np\n",
    "import os\n",
    "import traceback\n",
    "from collections import defaultdict\n",
    "from scipy import ndimage\n",
    "import json\n",
    "import codecs\n",
    "from svgpathtools import Path, Line\n",
    "from scipy.interpolate import griddata\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "\n",
    "# This is for dataset paths\n",
    "RASAM_PATH = '/home/msaeed3/mehreen/datasets/RASAM/sfr/'\n",
    "RASM_PATH = '/home/msaeed3/mehreen/datasets/RASM/sfr/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6462894",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_offset_mapping(img, ts, path, offset_1, offset_2, max_min = None, cube_size = None):\n",
    "    # cube_size = 80\n",
    "\n",
    "    offset_1_pts = []\n",
    "    offset_2_pts = []\n",
    "    # for t in ts:\n",
    "    for i in range(len(ts)):\n",
    "        t = ts[i]\n",
    "        pt = path.point(t)\n",
    "\n",
    "        norm = None\n",
    "        if i == 0:\n",
    "            norm = normal(pt, path.point(ts[i+1]))\n",
    "            norm = norm / dis(complex(0,0), norm)\n",
    "        elif i == len(ts)-1:\n",
    "            norm = normal(path.point(ts[i-1]), pt)\n",
    "            norm = norm / dis(complex(0,0), norm)\n",
    "        else:\n",
    "            norm1 = normal(path.point(ts[i-1]), pt)\n",
    "            norm1 = norm1 / dis(complex(0,0), norm1)\n",
    "            norm2 = normal(pt, path.point(ts[i+1]))\n",
    "            norm2 = norm2 / dis(complex(0,0), norm2)\n",
    "\n",
    "            norm = (norm1 + norm2)/2\n",
    "            norm = norm / dis(complex(0,0), norm)\n",
    "\n",
    "        offset_vector1 = offset_1 * norm\n",
    "        offset_vector2 = offset_2 * norm\n",
    "\n",
    "        pt1 = pt + offset_vector1\n",
    "        pt2 = pt + offset_vector2\n",
    "\n",
    "        offset_1_pts.append(complexToNpPt(pt1))\n",
    "        offset_2_pts.append(complexToNpPt(pt2))\n",
    "\n",
    "    offset_1_pts = np.array(offset_1_pts)\n",
    "    offset_2_pts = np.array(offset_2_pts)\n",
    "\n",
    "    h,w = img.shape[:2]\n",
    "\n",
    "    offset_source2 = np.array([(cube_size*i, 0) for i in range(len(offset_1_pts))], dtype=np.float32)\n",
    "    offset_source1 = np.array([(cube_size*i, cube_size) for i in range(len(offset_2_pts))], dtype=np.float32)\n",
    "\n",
    "    offset_source1 = offset_source1[::-1]\n",
    "    offset_source2 = offset_source2[::-1]\n",
    "\n",
    "    source = np.concatenate([offset_source1, offset_source2])\n",
    "    destination = np.concatenate([offset_1_pts, offset_2_pts])\n",
    "\n",
    "    source = source[:,::-1]\n",
    "    destination = destination[:,::-1]\n",
    "\n",
    "    n_w = int(offset_source2[:,0].max())\n",
    "    n_h = int(cube_size)\n",
    "\n",
    "    grid_x, grid_y = np.mgrid[0:n_h, 0:n_w]\n",
    "\n",
    "    grid_z = griddata(source, destination, (grid_x, grid_y), method='cubic')\n",
    "    map_x = np.append([], [ar[:,1] for ar in grid_z]).reshape(n_h,n_w)\n",
    "    map_y = np.append([], [ar[:,0] for ar in grid_z]).reshape(n_h,n_w)\n",
    "    map_x_32 = map_x.astype('float32')\n",
    "    map_y_32 = map_y.astype('float32')\n",
    "\n",
    "    rectified_to_warped_x = map_x_32\n",
    "    rectified_to_warped_y = map_y_32\n",
    "\n",
    "    grid_x, grid_y = np.mgrid[0:h, 0:w]\n",
    "    grid_z = griddata(source, destination, (grid_x, grid_y), method='cubic')\n",
    "    map_x = np.append([], [ar[:,1] for ar in grid_z]).reshape(h,w)\n",
    "    map_y = np.append([], [ar[:,0] for ar in grid_z]).reshape(h,w)\n",
    "    map_x_32 = map_x.astype('float32')\n",
    "    map_y_32 = map_y.astype('float32')\n",
    "\n",
    "    warped_to_rectified_x = map_x_32\n",
    "    warped_to_rectified_y = map_y_32\n",
    "\n",
    "    return rectified_to_warped_x, rectified_to_warped_y, warped_to_rectified_x, warped_to_rectified_y, max_min\n",
    "\n",
    "\n",
    "def dis(pt1, pt2):\n",
    "    a = (pt1.real - pt2.real)**2\n",
    "    b = (pt1.imag - pt2.imag)**2\n",
    "    return np.sqrt(a+b)\n",
    "\n",
    "def complexToNpPt(pt):\n",
    "    return np.array([pt.real, pt.imag], dtype=np.float32)\n",
    "\n",
    "def normal(pt1, pt2):\n",
    "    dif = pt1 - pt2\n",
    "    return complex(-dif.imag, dif.real)\n",
    "\n",
    "def find_t_spacing(path, cube_size):\n",
    "\n",
    "    l = path.length()\n",
    "    error = 0.01\n",
    "    init_step_size = cube_size / l\n",
    "\n",
    "    last_t = 0\n",
    "    cur_t = 0\n",
    "    pts = []\n",
    "    ts = [0]\n",
    "    pts.append(complexToNpPt(path.point(cur_t)))\n",
    "    path_lookup = {}\n",
    "    for target in np.arange(cube_size, int(l), cube_size):\n",
    "        step_size = init_step_size\n",
    "        for i in range(1000):\n",
    "            cur_length = dis(path.point(last_t), path.point(cur_t))\n",
    "            if np.abs(cur_length - cube_size) < error:\n",
    "                break\n",
    "\n",
    "            step_t = min(cur_t + step_size, 1.0)\n",
    "            step_l = dis(path.point(last_t), path.point(step_t))\n",
    "\n",
    "            if np.abs(step_l - cube_size) < np.abs(cur_length - cube_size):\n",
    "                cur_t = step_t\n",
    "                continue\n",
    "\n",
    "            step_t = max(cur_t - step_size, 0.0)\n",
    "            step_t = max(step_t, last_t)\n",
    "            step_t = max(step_t, 1.0)\n",
    "\n",
    "            step_l = dis(path.point(last_t), path.point(step_t))\n",
    "\n",
    "            if np.abs(step_l - cube_size) < np.abs(cur_length - cube_size):\n",
    "                cur_t = step_t\n",
    "                continue\n",
    "\n",
    "            step_size = step_size / 2.0\n",
    "\n",
    "        last_t = cur_t\n",
    "\n",
    "        ts.append(cur_t)\n",
    "        pts.append(complexToNpPt(path.point(cur_t)))\n",
    "\n",
    "    pts = np.array(pts)\n",
    "\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6373c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_str_to_int_tuples(df_col):\n",
    "    tmp_col = []\n",
    "    for ind, item in enumerate(df_col):\n",
    "        item = eval(item)    \n",
    "        tmp_col.append([(round(x[0]), round(x[1])) for x in item])\n",
    "    return tmp_col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acbd6d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_single_para(para_df, output_directory):\n",
    "    output_data = []\n",
    "    num_lines = len(para_df)\n",
    "    if os.path.exists(para_df.image_file.iloc[0]):\n",
    "        img = cv2.imread(para_df.image_file.iloc[0])\n",
    "        head, tail = os.path.split(para_df.image_file.iloc[0])\n",
    "        basename = 'base_' + tail\n",
    "        print('....', basename)\n",
    "\n",
    "    else:\n",
    "        img = cv2.imread(INPUT_PATH + para_df.image_file.iloc[0])\n",
    "        basename = 'base_' + para_df.image_file.iloc[0]\n",
    "    all_lines = \"\"\n",
    "    \n",
    "    # get rid of png/jpg extension\n",
    "    basename = basename[:-4]\n",
    "    for region in [0]:\n",
    "        region_output_data = []\n",
    "        #print('in region', region)\n",
    "        for ind, line in enumerate(para_df.line_number):\n",
    "            #print('in inner ind line', ind, line)\n",
    "            line_mask = line_extraction.extract_region_mask(img, para_df.polygon_pts[ind])\n",
    "            masked_img = img.copy()\n",
    "            masked_img[line_mask==0] = 0\n",
    "\n",
    "            summed_axis0 = (masked_img.astype(float) / 255).sum(axis=0)\n",
    "            summed_axis1 = (masked_img.astype(float) / 255).sum(axis=1)\n",
    "\n",
    "            non_zero_cnt0 = np.count_nonzero(summed_axis0) / float(len(summed_axis0))\n",
    "            non_zero_cnt1 = np.count_nonzero(summed_axis1) / float(len(summed_axis1))\n",
    "\n",
    "            avg_height0 = np.median(summed_axis0[summed_axis0 != 0])\n",
    "            avg_height1 = np.median(summed_axis1[summed_axis1 != 0])\n",
    "\n",
    "            avg_height = min(avg_height0, avg_height1)\n",
    "            if non_zero_cnt0 > non_zero_cnt1:\n",
    "                target_step_size = avg_height0\n",
    "            else:\n",
    "                target_step_size = avg_height1\n",
    "\n",
    "            paths = []\n",
    "            for i in range(len(para_df.baseline[ind])-1):\n",
    "                i_1 = i+1\n",
    "\n",
    "                p1 = para_df.baseline[ind][i]\n",
    "                p2 = para_df.baseline[ind][i_1]\n",
    "\n",
    "                p1_c = complex(*p1)\n",
    "                p2_c = complex(*p2)\n",
    "\n",
    "\n",
    "                paths.append(Line(p1_c, p2_c))\n",
    "\n",
    "\n",
    "            # Add a bit on the end\n",
    "            tan = paths[-1].unit_tangent(1.0)\n",
    "            p3_c = p2_c + target_step_size * tan\n",
    "            paths.append(Line(p2_c, p3_c))\n",
    "\n",
    "            path = Path(*paths)\n",
    "\n",
    "            ts = find_t_spacing(path, target_step_size)\n",
    "            \n",
    "\n",
    "            #Changing this causes issues in pretraining - not sure why\n",
    "            target_height = 32\n",
    "\n",
    "            rectified_to_warped_x, rectified_to_warped_y, warped_to_rectified_x, warped_to_rectified_y, max_min = generate_offset_mapping(masked_img, ts, path, 0, -2*target_step_size, cube_size = target_height)\n",
    "            warped_above = cv2.remap(line_mask, rectified_to_warped_x, rectified_to_warped_y, cv2.INTER_CUBIC, borderValue=(0,0,0))\n",
    "\n",
    "            rectified_to_warped_x, rectified_to_warped_y, warped_to_rectified_x, warped_to_rectified_y, max_min = generate_offset_mapping(masked_img, ts, path, 2*target_step_size, 0, cube_size = target_height)\n",
    "            warped_below = cv2.remap(line_mask, rectified_to_warped_x, rectified_to_warped_y, cv2.INTER_CUBIC, borderValue=(0,0,0))\n",
    "\n",
    "            above_scale =  np.max((warped_above.astype(float) / 255).sum(axis=0))\n",
    "            below_scale = np.max((warped_below.astype(float) / 255).sum(axis=0))\n",
    "\n",
    "            ab_sum = above_scale + below_scale\n",
    "            above = target_step_size * (above_scale/ab_sum)\n",
    "            below = target_step_size * (below_scale/ab_sum)\n",
    "\n",
    "            above = target_step_size * (above_scale/(target_height/2.0))\n",
    "            below = target_step_size * (below_scale/(target_height/2.0))\n",
    "            target_step_size = above + below\n",
    "            ts = find_t_spacing(path, target_step_size)\n",
    "            if len(ts) <= 1:\n",
    "                print('Not doing line', line)\n",
    "                continue\n",
    "            rectified_to_warped_x, rectified_to_warped_y, warped_to_rectified_x, warped_to_rectified_y, max_min = generate_offset_mapping(masked_img, ts, path, below, -above, cube_size=target_height)\n",
    "\n",
    "            ####MEHREEN COMMENT to prevent image from flipping\n",
    "            #rectified_to_warped_x = rectified_to_warped_x[::-1,::-1]\n",
    "            #rectified_to_warped_y = rectified_to_warped_y[::-1,::-1]\n",
    "            ###END MEHREEN COMMENT\n",
    "            warped_to_rectified_x = warped_to_rectified_x[::-1,::-1]\n",
    "            warped_to_rectified_y = warped_to_rectified_y[::-1,::-1]\n",
    "\n",
    "            warped = cv2.remap(img, rectified_to_warped_x, rectified_to_warped_y, cv2.INTER_CUBIC, borderValue=(255,255,255))\n",
    "\n",
    "            ####MEHREEN ADD\n",
    "            # Want to prevent image warping but we want coordinates to be warped\n",
    "            rectified_to_warped_x = rectified_to_warped_x[::-1,::-1]\n",
    "            rectified_to_warped_y = rectified_to_warped_y[::-1,::-1]\n",
    "\n",
    "            #### END MEHREEN ADD\n",
    "            \n",
    "            \n",
    "            mapping = np.stack([rectified_to_warped_y, rectified_to_warped_x], axis=2)\n",
    "\n",
    "            top_left = mapping[0,0,:] / np.array(img.shape[:2]).astype(np.float32)\n",
    "            btm_right = mapping[min(mapping.shape[0]-1, target_height-1), min(mapping.shape[1]-1, target_height-1),:] / np.array(img.shape[:2]).astype(np.float32)\n",
    "\n",
    "\n",
    "            line_points = []\n",
    "            for i in range(0,mapping.shape[1],target_height):\n",
    "\n",
    "                x0 = float(rectified_to_warped_x[0,i])\n",
    "                x1 = float(rectified_to_warped_x[-1,i])\n",
    "\n",
    "                y0 = float(rectified_to_warped_y[0,i])\n",
    "                y1 = float(rectified_to_warped_y[-1,i])\n",
    "\n",
    "                line_points.append({\n",
    "                    \"x0\": x0, #MEhreen change x0,\n",
    "                    \"x1\": x1, #Mehreen change x1,\n",
    "                    \"y0\": y1, #Mehreen change from y0,\n",
    "                    \"y1\": y0, #Mehreen change from y1\n",
    "                })\n",
    "                \n",
    "                \n",
    "                                \n",
    "            ###Mehreen add for viewing\n",
    "\n",
    "#            plt.imshow(img) # or display line warped\n",
    "#            print(\"****\", line_points)\n",
    "#            for coord in line_points:\n",
    "#                x = coord[\"x0\"]\n",
    "#                y = coord[\"y0\"]\n",
    "#                x1 = coord[\"x1\"]\n",
    "#                y1 = coord[\"y1\"]\n",
    "                #rect = patches.Rectangle((x, y), np.abs(x-coord[2]), np.abs(y-coord[3]), facecolor='green')\n",
    "#                rect = patches.Rectangle((x, y), 10, 10, facecolor='blue')\n",
    "#                rect1 = patches.Rectangle((x1, y1), 10, 10, facecolor='red')\n",
    "#                plt.gca().add_patch(rect)  \n",
    "#                plt.gca().add_patch(rect1)\n",
    "#            rect0 = patches.Rectangle((line_points[0][\"x0\"], line_points[0][\"y0\"]), 10, 10, facecolor='yellow') \n",
    "#            plt.gca().add_patch(rect0)\n",
    "#            plt.show()\n",
    "             ## ENd mehreen add for view   \n",
    "                \n",
    "            \n",
    "            output_file = os.path.join(output_directory, \n",
    "                          basename, \"{}~{}~{}.png\".format(basename, region, line))\n",
    "            warp_output_file = os.path.join(output_directory, basename, \"{}-{}.png\".format(basename, line))\n",
    "            warp_output_file_save = os.path.join(basename, \"{}-{}.png\".format(basename, str(len(region_output_data))))\n",
    "            save_file = os.path.join(basename, \"{}~{}~{}.png\".format(basename, region, line))\n",
    "            region_output_data.append({\n",
    "                \"gt\": para_df.ground_truth[ind],\n",
    "                \"image_path\": save_file,\n",
    "                \"sol\": line_points[0],\n",
    "                \"lf\": line_points,\n",
    "                \"hw_path\": warp_output_file #MEhreen commentwarp_output_file_save\n",
    "            })\n",
    "            #print('****', output_file)\n",
    "            if not os.path.exists(os.path.dirname(output_file)):\n",
    "                try:\n",
    "                    os.makedirs(os.path.dirname(output_file))\n",
    "                except OSError as exc:\n",
    "                    raise Exception(\"Could not write file\")\n",
    "\n",
    "            cv2.imwrite(warp_output_file, warped)\n",
    "\n",
    "        output_data.extend(region_output_data)\n",
    "\n",
    "    output_data_path =os.path.join(output_directory, basename, \"{}.json\".format(basename))\n",
    "    if not os.path.exists(os.path.dirname(output_data_path)):\n",
    "        os.makedirs(os.path.dirname(output_data_path))\n",
    "\n",
    "    with open(output_data_path, 'w') as f:\n",
    "        json.dump(output_data, f)\n",
    "\n",
    "    return output_data_path    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "374673a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total files in set Train: 200\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0071.jpg\n",
      ".... base_BULAC_MS_ARA_417_0015.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0056.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00088.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0054.jpg\n",
      ".... base_BULAC_MS_ARA_609_00073.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0186.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0117.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0123.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0185.jpg\n",
      ".... base_BULAC_MS_ARA_417_0051.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00035.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0172.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0176.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0178.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00060.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0022.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_417_0095.jpg\n",
      ".... base_BULAC_MS_ARA_417_0020.jpg\n",
      ".... base_BULAC_MS_ARA_417_0072.jpg\n",
      ".... base_BULAC_MS_ARA_609_00011.jpg\n",
      ".... base_BULAC_MS_ARA_609_00175.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0028.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0140.jpg\n",
      ".... base_BULAC_MS_ARA_417_0081.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0100.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0030.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0173.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0158.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00059.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0017.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_417_0025.jpg\n",
      ".... base_BULAC_MS_ARA_417_0067.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_417_0052.jpg\n",
      ".... base_BULAC_MS_ARA_609_00121.jpg\n",
      ".... base_BULAC_MS_ARA_417_0059.jpg\n",
      ".... base_BULAC_MS_ARA_417_0088.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00053.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00019.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0034.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0103.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0131.jpg\n",
      ".... base_BULAC_MS_ARA_417_0047.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0168.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0114.jpg\n",
      ".... base_BULAC_MS_ARA_417_0042.jpg\n",
      ".... base_BULAC_MS_ARA_417_0019.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0042.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00043.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_417_0064.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00086.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_417_0085.jpg\n",
      ".... base_BULAC_MS_ARA_609_00006.jpg\n",
      ".... base_BULAC_MS_ARA_417_0094.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_417_0043.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0142.jpg\n",
      ".... base_BULAC_MS_ARA_609_00171.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0128.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_417_0021.jpg\n",
      ".... base_BULAC_MS_ARA_609_00149.jpg\n",
      ".... base_BULAC_MS_ARA_609_00099.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00080.jpg\n",
      ".... base_BULAC_MS_ARA_609_00037.jpg\n",
      ".... base_BULAC_MS_ARA_417_0061.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0127.jpg\n",
      ".... base_BULAC_MS_ARA_609_00199.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00136.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_417_0030.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0118.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0080.jpg\n",
      ".... base_BULAC_MS_ARA_417_0036.jpg\n",
      ".... base_BULAC_MS_ARA_609_00125.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00135.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00179.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_417_0058.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0092.jpg\n",
      ".... base_BULAC_MS_ARA_609_00021.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00012.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0020.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0120.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0169.jpg\n",
      ".... base_BULAC_MS_ARA_417_0034.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00184.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00133.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0126.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0012.jpg\n",
      "Not doing line 32\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_417_0022.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0069.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0094.jpg\n",
      ".... base_BULAC_MS_ARA_417_0009.jpg\n",
      ".... base_BULAC_MS_ARA_609_00156.jpg\n",
      ".... base_BULAC_MS_ARA_417_0017.jpg\n",
      ".... base_BULAC_MS_ARA_609_00122.jpg\n",
      ".... base_BULAC_MS_ARA_417_0046.jpg\n",
      "done 100\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0038.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0061.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_417_0076.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0013.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_417_0035.jpg\n",
      ".... base_BULAC_MS_ARA_609_00022.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00126.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_417_0007.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_417_0087.jpg\n",
      ".... base_BULAC_MS_ARA_609_00042.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0119.jpg\n",
      ".... base_BULAC_MS_ARA_417_0011.jpg\n",
      ".... base_BULAC_MS_ARA_417_0027.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0161.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_417_0091.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0047.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0143.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0192.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00057.jpg\n",
      ".... base_BULAC_MS_ARA_609_00040.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00085.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0075.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0046.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00075.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_417_0033.jpg\n",
      ".... base_BULAC_MS_ARA_609_00091.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_417_0029.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00174.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0174.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0132.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0067.jpg\n",
      ".... base_BULAC_MS_ARA_609_00202.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0050.jpg\n",
      ".... base_BULAC_MS_ARA_417_0069.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0052.jpg\n",
      ".... base_BULAC_MS_ARA_417_0083.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00026.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0104.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00025.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00123.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_417_0068.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0107.jpg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0072.jpg\n",
      ".... base_BULAC_MS_ARA_609_00064.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0124.jpg\n",
      ".... base_BULAC_MS_ARA_609_00159.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0152.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_417_0049.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_417_0077.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0108.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0033.jpg\n",
      ".... base_BULAC_MS_ARA_417_0006.jpg\n",
      ".... base_BULAC_MS_ARA_417_0003.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00139.jpg\n",
      ".... base_BULAC_MS_ARA_417_0050.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00082.jpg\n",
      ".... base_BULAC_MS_ARA_417_0060.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0148.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_417_0004.jpg\n",
      ".... base_BULAC_MS_ARA_609_00087.jpg\n",
      "Not doing line 1\n",
      ".... base_BULAC_MS_ARA_609_00103.jpg\n",
      ".... base_BULAC_MS_ARA_609_00070.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00097.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00168.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00032.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0063.jpg\n",
      ".... base_BULAC_MS_ARA_609_00007.jpg\n",
      ".... base_BULAC_MS_ARA_609_00016.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0031.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00167.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0058.jpg\n",
      ".... base_BULAC_MS_ARA_609_00110.jpg\n",
      "Not doing line 36\n",
      ".... base_BULAC_MS_ARA_609_00186.jpg\n",
      ".... base_BULAC_MS_ARA_609_00106.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0062.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00004.jpg\n",
      ".... base_BULAC_MS_ARA_609_00049.jpg\n",
      ".... base_BULAC_MS_ARA_417_0062.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0041.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0078.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0134.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0085.jpg\n",
      ".... base_BULAC_MS_ARA_417_0056.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00188.jpg\n",
      ".... base_BULAC_MS_ARA_609_00195.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0137.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0147.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0081.jpg\n",
      ".... base_BULAC_MS_ARA_417_0013.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0162.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0155.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00177.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0095.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_417_0070.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_417_0082.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00014.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_609_00114.jpg\n",
      ".... base_BULAC_MS_ARA_609_00101.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0099.jpg\n",
      "Already processed  /home/msaeed3/mehreen/datasets/RASAM/BULAC_MS_ARA_1977_0066.jpg\n",
      "done 200\n",
      "Total files in set Valid: 20\n",
      ".... base_BULAC_MS_ARA_609_00010.jpg\n",
      ".... base_BULAC_MS_ARA_417_0039.jpg\n",
      ".... base_BULAC_MS_ARA_417_0066.jpg\n",
      ".... base_BULAC_MS_ARA_609_00193.jpg\n",
      ".... base_BULAC_MS_ARA_417_0016.jpg\n",
      ".... base_BULAC_MS_ARA_609_00203.jpg\n",
      ".... base_BULAC_MS_ARA_417_0044.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0145.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0093.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0198.jpg\n",
      ".... base_BULAC_MS_ARA_1977_0090.jpg\n",
      ".... base_BULAC_MS_ARA_609_00109.jpg\n",
      "Not doing line 28\n",
      ".... base_BULAC_MS_ARA_417_0075.jpg\n",
      ".... base_BULAC_MS_ARA_609_00045.jpg\n",
      ".... base_BULAC_MS_ARA_417_0041.jpg\n",
      ".... base_BULAC_MS_ARA_609_00030.jpg\n",
      ".... base_BULAC_MS_ARA_417_0098.jpg\n",
      ".... base_BULAC_MS_ARA_417_0012.jpg\n",
      ".... base_BULAC_MS_ARA_417_0040.jpg\n",
      ".... base_BULAC_MS_ARA_609_00041.jpg\n"
     ]
    }
   ],
   "source": [
    "def process_dir(path, set_name):\n",
    "\n",
    "    df = pd.read_csv(os.path.join(path, set_name+'.csv'))\n",
    "    df.baseline = convert_str_to_int_tuples(df.baseline)\n",
    "    #df.baseline = rotate_baseline_list(df.baseline)\n",
    "    df.polygon_pts = convert_str_to_int_tuples(df.polygon_pts)\n",
    "    #df.polygon_pts = rotate_poly_list(df.polygon_pts) \n",
    "    \n",
    "    files = df.image_file\n",
    "    print(f'Total files in set {set_name}: {len(set(files))}')\n",
    "    \n",
    "    all_ground_truth = []\n",
    "    for para_numb in set(df.paragraph_number):\n",
    "        para_df = df[df.paragraph_number == para_numb]\n",
    "        para_df = para_df.copy()\n",
    "        para_df = para_df.reset_index(drop=True)\n",
    "        head, tail = os.path.split(para_df.image_file.iloc[0])\n",
    "        basename = 'base_' + tail\n",
    "        basename = basename[:-4]\n",
    "        ### CHECK IF THEY NEED TO BE PROCESSED AGAIN\n",
    "        output_data_path = os.path.join(RASAM_PATH+set_name, basename, \"{}.json\".format(basename))\n",
    "        if not os.path.exists(os.path.dirname(output_data_path)):\n",
    "            json_path = handle_single_para(para_df, RASAM_PATH+set_name)  \n",
    "        else:\n",
    "            print('Already processed ', img_path)\n",
    "            json_path = output_data_path\n",
    "            \n",
    "        \n",
    "        all_ground_truth.append([json_path, img_path])\n",
    "        if len(all_ground_truth)%100 == 0:\n",
    "            print('done', len(all_ground_truth))\n",
    "        \n",
    "    return all_ground_truth\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "def main_func():\n",
    "    input_paths = ['/home/msaeed3/mehreen/datasets/RASAM/regions', \n",
    "                   '/home/msaeed3/mehreen/datasets/RASM/regions']\n",
    "\n",
    "    set_name = ['Train', 'Valid']\n",
    "    \n",
    "    training_output_json = os.path.join(RASAM_PATH, set_name[0]+'.json')\n",
    "    validation_output_json = os.path.join(RASAM_PATH, set_name[1]+'.json')\n",
    "    \n",
    "    train_ground_truth = process_RASAM_dir(set_name[0])\n",
    "    valid_ground_truth = process_RASAM_dir(set_name[1])\n",
    "\n",
    "\n",
    "\n",
    "    with open(training_output_json, 'w') as f:\n",
    "        json.dump(train_ground_truth, f)\n",
    "\n",
    "    with open(validation_output_json, 'w') as f:\n",
    "        json.dump(valid_ground_truth, f)\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "main_RASAM_preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064dac63",
   "metadata": {},
   "source": [
    "#Uncomment this cell to check for a single file\n",
    "\n",
    "check_file = 'BULAC_MS_ARA_609_00014' \n",
    "set_name = 'Train'\n",
    "\n",
    "df = pd.read_csv(os.path.join(RASAM_PATH, 'Train'+'.csv'))\n",
    "df.baseline = convert_str_to_int_tuples(df.baseline)\n",
    "#df.baseline = rotate_baseline_list(df.baseline)\n",
    "df.polygon_pts = convert_str_to_int_tuples(df.polygon_pts)\n",
    "#df.polygon_pts = rotate_poly_list(df.polygon_pts) \n",
    "\n",
    "files = df.image_file\n",
    "\n",
    "all_ground_truth = []\n",
    "for img_path in set(files):\n",
    "\n",
    "    if check_file in img_path:\n",
    "        print('***')\n",
    "        para_df = df[df.image_file == img_path]\n",
    "        para_df = para_df.copy()\n",
    "        para_df = para_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "        json_path = handle_single_para(para_df, RASAM_PATH+set_name)       \n",
    "        print(json_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acfa9729",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_output_json' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtraining_output_json\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_output_json' is not defined"
     ]
    }
   ],
   "source": [
    "training_output_json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
